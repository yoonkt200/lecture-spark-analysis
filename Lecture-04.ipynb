{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD Persistence\n",
    "- RDD로 캐시를 수행하는 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd = persistedRDD ParallelCollectionRDD[0] at makeRDD at <console>:29\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "persistedRDD ParallelCollectionRDD[0] at makeRDD at <console>:29"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.storage.StorageLevel\n",
    "\n",
    "val rdd = sc.makeRDD(1 to 10000)\n",
    "rdd.setName(\"persistedRDD\")\n",
    "rdd.persist(StorageLevel.DISK_ONLY) // 이때까지 실제로 캐시가 이뤄지지는 않음\n",
    "rdd.count // -> action 수행. 실제로 캐시가 이루어지는 부분\n",
    "// 웹 UI 확인 (Storage 항목에서 캐시된 RDD 확인)\n",
    "rdd.unpersist()\n",
    "// 웹 UI 확인 (Storage 항목에서 삭제된 RDD 확인)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "-----\n",
    "## Whole File-Based RDDs\n",
    "- json같은 파일은 한줄 한줄이 의미있는 것이 아닌, 전체가 의미있는 데이터\n",
    "- 이러한 데이터는 wholeTextFiles로 한번에 처리해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myRDD = ./*.json MapPartitionsRDD[2] at wholeTextFiles at <console>:30\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "./*.json MapPartitionsRDD[2] at wholeTextFiles at <console>:30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.util.parsing.json.JSON\n",
    "\n",
    "val myRDD = sc.wholeTextFiles(\"./*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((file:/home/jovyan/work/file2.json,\"{\n",
       "  \"firstName\":\"Barney\",\n",
       "  \"lastName\":\"Rubble\",\n",
       "  \"userId\":\"234\"\n",
       "}\n",
       "\"), (file:/home/jovyan/work/file1.json,\"{\n",
       "  \"firstName\":\"Fred\",\n",
       "  \"lastName\":\"Flintstone\",\n",
       "  \"userId\":\"123\"\n",
       "}\n",
       "\"))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(file:/home/jovyan/work/file2.json,{\n",
       "  \"firstName\":\"Barney\",\n",
       "  \"lastName\":\"Rubble\",\n",
       "  \"userId\":\"234\"\n",
       "}\n",
       "), (file:/home/jovyan/work/file1.json,{\n",
       "  \"firstName\":\"Fred\",\n",
       "  \"lastName\":\"Flintstone\",\n",
       "  \"userId\":\"123\"\n",
       "}\n",
       ")]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myRDD2 = MapPartitionsRDD[5] at map at <console>:32\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[5] at map at <console>:32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// var myRDD2 = myRDD.map(pair => JSON.parseFull(pair._2)) \n",
    "var myRDD2 = myRDD.map(pair => JSON.parseFull(pair._2).get.asInstanceOf[Map[String,String]])\n",
    "// get 함수 : return contained element if it exists\n",
    "// asInstanceOf: 캐스팅 연산자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map(firstName -> Barney, lastName -> Rubble, userId -> 234)\n",
      "Map(firstName -> Fred, lastName -> Flintstone, userId -> 123)\n"
     ]
    }
   ],
   "source": [
    "myRDD2.take(2).foreach(x => println(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barney\n",
      "Fred\n"
     ]
    }
   ],
   "source": [
    "myRDD2.take(2).foreach(x => println(x.getOrElse(\"firstName\",null)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "-----\n",
    "## Pair RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (key, value) ... 으로 pair로 묶여있는 RDD들의 집합.\n",
    "- Map-Reduce는 Spark에서 pair RDDs로 동작함.\n",
    "-----\n",
    "- Map phase : map, flatMap, filter, keyBy...\n",
    "- Reduce phase : reduceByKey, sortByKey, mean...\n",
    "\n",
    "--> 스파크의 대부분은 map-reduce 스타일의 api로 구성되어있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "-----\n",
    "## Shared Variables\n",
    "- Broadcast : 여러 worker들에게 같은 값의 변수를 전파하는 것.\n",
    "- Accumulators : 작업 수행 중 발생하는 일 세기 등, 누적값을 지속적으로 사용해야 하는 경우에 사용한다. multi-workers가 single location을 저장소로 사용하는 셈."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "broadcastVar = Broadcast(10)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// broadcast lab\n",
    "val broadcastVar = sc.broadcast(Array(1, 2, 3))\n",
    "broadcastVar.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accum = LongAccumulator(id: 225, name: Some(My Accumulator), value: 10)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// accum lab\n",
    "val accum = sc.longAccumulator(\"My Accumulator\")\n",
    "sc.parallelize(Array(1, 2, 3, 4)).repartition(10).foreach(x => accum.add(x))  //한번이 아니라 여러 번 반복 한다면….\n",
    "accum.value  //계속 누적…."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(Array(1, 2, 3, 4)).repartition(10).foreach(x => accum.add(x))  //한번이 아니라 여러 번 반복 한다면….\n",
    "accum.value  //계속 누적…."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(Array(1, 2, 3, 4)).repartition(10).foreach(x => accum.add(x))  //한번이 아니라 여러 번 반복 한다면….\n",
    "accum.value  //계속 누적…."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
